# Direct EriDiffusion → FLAME Migration Agents

**Mission**: Replace ALL Candle dependencies with direct FLAME usage. NO compatibility layers, NO wrappers, NO abstraction overhead.

**Architecture Rule**: Clean direct migration - EriDiffusion talks directly to FLAME.

## Agent 1: Candle Purge Agent
**Mission**: Find and eliminate every single Candle dependency

### 1. Complete Candle Elimination

#### Remove All Candle Imports
```bash
# Find every Candle reference and kill it
cd eridiffusion/

# Search and destroy all Candle imports
find src/ -name "*.rs" -exec grep -l "candle" {} \; | while read file; do
    echo "Processing: $file"
    
    # Remove Candle imports
    sed -i '/use candle/d' "$file"
    sed -i '/candle::/d' "$file"
    sed -i '/candle_/d' "$file"
    
    echo "Cleaned: $file"
done

# Remove Candle from Cargo.toml
sed -i '/candle/d' Cargo.toml
```

#### Replace With Direct FLAME Imports
```rust
// In EVERY file that used Candle, add:
use flame::{Tensor, Device, DType, Result};
use flame::nn::{Conv2d, Linear, LayerNorm, GroupNorm};
use flame::optim::{Adam, AdamW, SGD};

// NO candle_compat
// NO compatibility layers  
// NO wrappers
// ONLY direct FLAME usage
```

#### Verify Complete Removal
```bash
# These should return ZERO results:
grep -r "candle" src/ --include="*.rs" | wc -l
grep -r "VarBuilder" src/ --include="*.rs" | wc -l
grep -r "candle_" Cargo.toml | wc -l

# If any results found, eliminate them
```

### Agent 1 Success Criteria
- [ ] Zero Candle imports in any .rs file
- [ ] Zero Candle dependencies in Cargo.toml
- [ ] All files have FLAME imports instead
- [ ] Complete Candle purge verified

---

## Agent 2: Core API Replacement Agent
**Mission**: Replace Candle APIs with direct FLAME equivalents

### 1. Tensor Operations Direct Replacement

#### Basic Tensor Creation
```rust
// Replace ALL instances of Candle tensor creation:

// OLD Candle API:
let tensor = Tensor::zeros(&shape, DType::F32, &device)?;
let tensor = Tensor::ones(&shape, DType::F32, &device)?;
let tensor = Tensor::randn(&shape, DType::F32, &device)?;

// NEW Direct FLAME API:
let tensor = Tensor::zeros(&shape, device)?;
let tensor = Tensor::ones(&shape, device)?;
let tensor = Tensor::randn(&shape, device)?;
```

#### Tensor Operations
```rust
// Replace ALL tensor operations:

// OLD Candle:
tensor.to_device(&device)?
tensor.to_dtype(DType::F16)?
tensor.broadcast_as(&other_shape)?

// NEW Direct FLAME:
tensor.to(device)?
tensor.to_dtype(DType::F16)?
tensor.broadcast_to(&other_shape)?
```

#### Arithmetic Operations
```rust
// Ensure these work with FLAME tensors:
let result = &tensor1 + &tensor2;
let result = &tensor1 * &tensor2;
let result = &tensor1 - &tensor2;
let result = &tensor1 / &tensor2;

// Matrix operations:
let result = tensor1.matmul(&tensor2)?;
let result = tensor.transpose(-1, -2)?;
```

### 2. Model Loading Direct Replacement

#### Eliminate VarBuilder Pattern Completely
```rust
// OLD Candle VarBuilder (ELIMINATE):
let vb = unsafe { VarBuilder::from_mmaped_safetensors(&[path], dtype, &device)? };
let weight = vb.get(&[dims], "layer.weight")?;

// NEW Direct FLAME Loading:
let weights_map = flame::load_safetensors(path, device)?;
let weight = weights_map.get("layer.weight")
    .ok_or_else(|| Error::WeightNotFound("layer.weight"))?;

// Create helper for model loading:
pub struct WeightLoader {
    weights: HashMap<String, Tensor>,
}

impl WeightLoader {
    pub fn from_safetensors(path: &str, device: Device) -> Result<Self> {
        let weights = flame::load_safetensors(path, device)?;
        Ok(Self { weights })
    }
    
    pub fn get(&self, key: &str) -> Result<&Tensor> {
        self.weights.get(key).ok_or_else(|| Error::WeightNotFound(key))
    }
    
    pub fn tensor(&self, key: &str, shape: &[usize]) -> Result<Tensor> {
        let weight = self.get(key)?;
        if weight.shape() != shape {
            return Err(Error::ShapeMismatch);
        }
        Ok(weight.clone())
    }
}
```

### 3. Neural Network Layers Direct Replacement

#### Convert All Layer Constructors
```rust
// OLD Candle layer creation:
pub struct MyConv {
    conv: candle_nn::Conv2d,
}

impl MyConv {
    pub fn new(vb: VarBuilder, in_ch: usize, out_ch: usize) -> Result<Self> {
        let conv = candle_nn::conv2d(in_ch, out_ch, 3, Default::default(), vb.pp("conv"))?;
        Ok(Self { conv })
    }
}

// NEW Direct FLAME:
pub struct MyConv {
    conv: flame::nn::Conv2d,
}

impl MyConv {
    pub fn new(weights: &WeightLoader, in_ch: usize, out_ch: usize) -> Result<Self> {
        let weight = weights.tensor("conv.weight", &[out_ch, in_ch, 3, 3])?;
        let bias = weights.tensor("conv.bias", &[out_ch])?;
        let conv = flame::nn::Conv2d::from_weights(weight, Some(bias), 1, 1)?;
        Ok(Self { conv })
    }
    
    // Alternative: Create new layer
    pub fn new_random(in_ch: usize, out_ch: usize, device: Device) -> Result<Self> {
        let conv = flame::nn::Conv2d::new(in_ch, out_ch, 3, 1, 1, device)?;
        Ok(Self { conv })
    }
}
```

### Agent 2 Success Criteria
- [ ] All tensor operations use direct FLAME API
- [ ] VarBuilder completely eliminated
- [ ] Direct weight loading implemented
- [ ] All layers use FLAME nn modules

---

## Agent 3: Training System Migration Agent
**Mission**: Convert training loops to use FLAME's mutable gradients

### 1. Replace Immutable Candle Training

#### Convert Training Loops
```rust
// OLD Candle training (BROKEN - immutable gradients):
for batch in dataloader {
    let output = model.forward(&batch.input)?;
    let loss = loss_fn(&output, &batch.target)?;
    // ❌ Can't update gradients - Candle limitation
}

// NEW FLAME training (WORKING - mutable gradients):
let mut optimizer = flame::optim::AdamW::new(0.001, 0.9, 0.999, 1e-8, 0.01);

for batch in dataloader {
    // Forward pass
    let output = model.forward(&batch.input)?;
    let loss = loss_fn(&output, &batch.target)?;
    
    // Backward pass - THIS WORKS WITH FLAME!
    let grad_map = loss.backward()?;
    
    // Update parameters - MUTABLE GRADIENTS!
    optimizer.step(&model.parameters(), &grad_map)?;
    optimizer.zero_grad();
}
```

### 2. Parameter Management

#### Implement Parameter Access
```rust
// Each model needs to expose parameters for optimizer
pub trait FLAMEModel {
    fn parameters(&self) -> Vec<&flame::Parameter>;
    fn named_parameters(&self) -> HashMap<String, &flame::Parameter>;
}

impl FLAMEModel for UNetModel {
    fn parameters(&self) -> Vec<&flame::Parameter> {
        let mut params = Vec::new();
        
        // Collect all conv layer parameters
        for conv in &self.conv_layers {
            params.extend(conv.parameters());
        }
        
        // Collect all linear layer parameters
        for linear in &self.linear_layers {
            params.extend(linear.parameters());
        }
        
        params
    }
}
```

### 3. Optimizer Integration

#### Direct Optimizer Usage
```rust
// Configure optimizers for different components
pub struct TrainingConfig {
    unet_lr: f32,
    text_encoder_lr: f32,
    vae_lr: f32,
}

pub struct MultiOptimizer {
    unet_optimizer: flame::optim::AdamW,
    text_encoder_optimizer: flame::optim::AdamW,
}

impl MultiOptimizer {
    pub fn step(&mut self, 
                unet_params: &[&flame::Parameter], 
                text_encoder_params: &[&flame::Parameter],
                grad_map: &GradientMap) -> Result<()> {
        
        self.unet_optimizer.step(unet_params, grad_map)?;
        self.text_encoder_optimizer.step(text_encoder_params, grad_map)?;
        
        Ok(())
    }
}
```

### Agent 3 Success Criteria
- [ ] All training loops use FLAME gradients
- [ ] Parameter management implemented
- [ ] Optimizers work with FLAME parameters
- [ ] Gradient updates actually modify weights

---

## Agent 4: Model Architecture Migration Agent
**Mission**: Convert specific model implementations (VAE, UNet, CLIP, etc.)

### 1. VAE Model Migration

#### Convert VAE to Direct FLAME
```rust
// OLD Candle VAE:
pub struct VAE {
    encoder: VAEEncoder,
    decoder: VAEDecoder,
}

impl VAE {
    pub fn load(vb: VarBuilder) -> Result<Self> {
        let encoder = VAEEncoder::load(vb.pp("encoder"))?;
        let decoder = VAEDecoder::load(vb.pp("decoder"))?;
        Ok(Self { encoder, decoder })
    }
}

// NEW Direct FLAME VAE:
pub struct VAE {
    encoder: VAEEncoder,
    decoder: VAEDecoder,
}

impl VAE {
    pub fn load(weights: &WeightLoader) -> Result<Self> {
        let encoder = VAEEncoder::load(weights, "encoder")?;
        let decoder = VAEDecoder::load(weights, "decoder")?;
        Ok(Self { encoder, decoder })
    }
    
    pub fn encode(&self, x: &Tensor) -> Result<Tensor> {
        self.encoder.forward(x)
    }
    
    pub fn decode(&self, z: &Tensor) -> Result<Tensor> {
        self.decoder.forward(z)
    }
}

impl FLAMEModel for VAE {
    fn parameters(&self) -> Vec<&flame::Parameter> {
        [self.encoder.parameters(), self.decoder.parameters()].concat()
    }
}
```

### 2. UNet Model Migration

#### Convert UNet Architecture
```rust
pub struct UNet2DConditionModel {
    conv_in: flame::nn::Conv2d,
    down_blocks: Vec<DownBlock2D>,
    mid_block: MidBlock2D,
    up_blocks: Vec<UpBlock2D>,
    conv_out: flame::nn::Conv2d,
}

impl UNet2DConditionModel {
    pub fn load(weights: &WeightLoader) -> Result<Self> {
        // Load each component directly from weights
        let conv_in = load_conv_layer(weights, "conv_in", 4, 320)?;
        
        let mut down_blocks = Vec::new();
        for i in 0..4 {
            let block = DownBlock2D::load(weights, &format!("down_blocks.{}", i))?;
            down_blocks.push(block);
        }
        
        let mid_block = MidBlock2D::load(weights, "mid_block")?;
        
        let mut up_blocks = Vec::new();
        for i in 0..4 {
            let block = UpBlock2D::load(weights, &format!("up_blocks.{}", i))?;
            up_blocks.push(block);
        }
        
        let conv_out = load_conv_layer(weights, "conv_out", 320, 4)?;
        
        Ok(Self {
            conv_in,
            down_blocks,
            mid_block,
            up_blocks,
            conv_out,
        })
    }
    
    pub fn forward(&self, 
                   latent: &Tensor, 
                   timestep: &Tensor, 
                   encoder_hidden_states: &Tensor) -> Result<Tensor> {
        
        let mut sample = self.conv_in.forward(latent)?;
        
        // Down blocks
        let mut down_samples = Vec::new();
        for down_block in &self.down_blocks {
            sample = down_block.forward(&sample, timestep, encoder_hidden_states)?;
            down_samples.push(sample.clone());
        }
        
        // Mid block
        sample = self.mid_block.forward(&sample, timestep, encoder_hidden_states)?;
        
        // Up blocks
        for (up_block, down_sample) in self.up_blocks.iter().zip(down_samples.iter().rev()) {
            sample = up_block.forward(&sample, down_sample, timestep, encoder_hidden_states)?;
        }
        
        // Output
        self.conv_out.forward(&sample)
    }
}
```

### 3. Text Encoder Migration

#### Convert CLIP Text Encoder
```rust
pub struct CLIPTextModel {
    embeddings: CLIPTextEmbeddings,
    encoder: CLIPEncoder,
    final_layer_norm: flame::nn::LayerNorm,
}

impl CLIPTextModel {
    pub fn load(weights: &WeightLoader) -> Result<Self> {
        let embeddings = CLIPTextEmbeddings::load(weights, "text_model.embeddings")?;
        let encoder = CLIPEncoder::load(weights, "text_model.encoder")?;
        let final_layer_norm = load_layer_norm(weights, "text_model.final_layer_norm", 768)?;
        
        Ok(Self {
            embeddings,
            encoder,
            final_layer_norm,
        })
    }
    
    pub fn forward(&self, input_ids: &Tensor) -> Result<Tensor> {
        let hidden_states = self.embeddings.forward(input_ids)?;
        let encoded = self.encoder.forward(&hidden_states)?;
        self.final_layer_norm.forward(&encoded)
    }
}
```

### Agent 4 Success Criteria
- [ ] VAE model fully migrated to FLAME
- [ ] UNet model fully migrated to FLAME
- [ ] CLIP text encoder migrated to FLAME
- [ ] All models work with FLAME tensors
- [ ] Models can be trained with FLAME gradients

---

## Agent 5: Data Pipeline Migration Agent
**Mission**: Make data loading output FLAME tensors directly

### 1. DataLoader Migration

#### Convert Image Loading to FLAME
```rust
// OLD Candle DataLoader:
impl DataLoader {
    fn load_batch(&self) -> Result<Batch> {
        let mut images = Vec::new();
        
        for image_path in &self.batch_paths {
            let img = image::open(image_path)?;
            let tensor = candle_tensor_from_image(img, &self.device)?; // Candle
            images.push(tensor);
        }
        
        let batch_tensor = Tensor::stack(&images, 0)?; // Candle
        Ok(Batch { images: batch_tensor })
    }
}

// NEW Direct FLAME DataLoader:
impl DataLoader {
    fn load_batch(&self) -> Result<Batch> {
        let mut images = Vec::new();
        
        for image_path in &self.batch_paths {
            let img = image::open(image_path)?;
            let tensor = flame_tensor_from_image(img, self.device)?; // FLAME
            images.push(tensor);
        }
        
        let batch_tensor = flame::Tensor::stack(&images, 0)?; // FLAME
        Ok(Batch { images: batch_tensor })
    }
}

// Implement image → FLAME tensor conversion
fn flame_tensor_from_image(img: DynamicImage, device: Device) -> Result<Tensor> {
    let (width, height) = img.dimensions();
    let rgb_img = img.to_rgb8();
    let pixels: Vec<f32> = rgb_img.pixels()
        .flat_map(|p| [p[0] as f32 / 255.0, p[1] as f32 / 255.0, p[2] as f32 / 255.0])
        .collect();
    
    let tensor = flame::Tensor::from_vec(pixels, &[3, height as usize, width as usize], device)?;
    
    // Normalize to [-1, 1] for diffusion models
    let normalized = (&tensor * 2.0)? - 1.0;
    Ok(normalized)
}
```

### 2. Preprocessing Pipeline

#### Convert All Transforms to FLAME
```rust
pub struct ImageTransforms {
    target_size: (usize, usize),
    device: Device,
}

impl ImageTransforms {
    pub fn apply(&self, tensor: &Tensor) -> Result<Tensor> {
        // Resize using FLAME operations
        let resized = flame::vision::resize(tensor, self.target_size)?;
        
        // Center crop using FLAME operations  
        let cropped = flame::vision::center_crop(&resized, self.target_size)?;
        
        // Random flip (if training)
        let flipped = if rand::random::<bool>() {
            flame::vision::horizontal_flip(&cropped)?
        } else {
            cropped
        };
        
        Ok(flipped)
    }
}
```

### Agent 5 Success Criteria
- [ ] DataLoader outputs FLAME tensors
- [ ] Image preprocessing uses FLAME operations
- [ ] No Candle tensor conversions
- [ ] Direct FLAME pipeline throughout

---

## Agent 6: Integration Validation Agent
**Mission**: Verify complete migration works end-to-end

### 1. Complete Training Pipeline Test

#### End-to-End SDXL LoRA Training
```rust
#[test]
fn test_complete_sdxl_lora_training_direct_flame() {
    let device = Device::Cuda(0);
    
    // Load all models with direct FLAME
    let weights = WeightLoader::from_safetensors("/path/to/sdxl.safetensors", device)?;
    let vae = VAE::load(&weights)?;
    let unet = UNet2DConditionModel::load(&weights)?;
    let text_encoder = CLIPTextModel::load(&weights)?;
    
    // Setup LoRA on UNet
    let lora_config = LoRAConfig { rank: 16, alpha: 16 };
    let mut lora_unet = LoRAUNet::new(unet, lora_config)?;
    
    // Direct FLAME optimizer
    let mut optimizer = flame::optim::AdamW::new(0.0001, 0.9, 0.999, 1e-8, 0.01);
    
    // Direct FLAME dataloader
    let dataloader = FLAMEDataLoader::new("/path/to/images", device)?;
    
    let mut losses = Vec::new();
    
    // Training loop with NO compatibility layers
    for (step, batch) in dataloader.take(100).enumerate() {
        // Encode images to latents (VAE)
        let latents = vae.encode(&batch.images)?;
        
        // Encode text (CLIP)
        let text_embeds = text_encoder.forward(&batch.input_ids)?;
        
        // Add noise (diffusion forward process)
        let noise = flame::Tensor::randn_like(&latents)?;
        let timesteps = flame::Tensor::randint(0, 1000, &[batch.batch_size], device)?;
        let noisy_latents = scheduler.add_noise(&latents, &noise, &timesteps)?;
        
        // UNet prediction (with LoRA)
        let pred_noise = lora_unet.forward(&noisy_latents, &timesteps, &text_embeds)?;
        
        // Diffusion loss
        let loss = mse_loss(&pred_noise, &noise)?;
        losses.push(loss.item::<f32>());
        
        // Backward pass (FLAME mutable gradients!)
        let grad_map = loss.backward()?;
        
        // Update LoRA parameters
        optimizer.step(&lora_unet.lora_parameters(), &grad_map)?;
        optimizer.zero_grad();
        
        if step % 10 == 0 {
            println!("Step {}: Loss = {:.6}", step, loss.item::<f32>());
        }
    }
    
    // Verify convergence
    let initial_loss = losses[0];
    let final_loss = losses[losses.len() - 1];
    assert!(final_loss < initial_loss * 0.8, "Training should converge");
    
    // Save LoRA in ComfyUI format
    lora_unet.save_lora("direct_flame_lora.safetensors")?;
    
    // Verify LoRA format
    let lora_weights = flame::load_safetensors("direct_flame_lora.safetensors", device)?;
    assert!(lora_weights.contains_key("lora_unet_down_blocks_0_attentions_0_to_k.lora_down.weight"));
    
    println!("✅ Complete direct FLAME training successful!");
}
```

### 2. Performance Validation

#### Memory and Speed Comparison
```rust
#[test]
fn test_direct_flame_vs_candle_performance() {
    let device = Device::Cuda(0);
    
    // Test memory usage
    let initial_memory = get_gpu_memory_usage()?;
    
    // Create large model with direct FLAME
    let model = create_large_diffusion_model_flame(device)?;
    let dataloader = FLAMEDataLoader::new("/path/to/data", device)?;
    
    // Time training steps
    let start_time = std::time::Instant::now();
    
    for batch in dataloader.take(50) {
        let loss = model.training_step(&batch)?;
        let grad_map = loss.backward()?;
        // ... optimizer step
    }
    
    let training_time = start_time.elapsed();
    let final_memory = get_gpu_memory_usage()?;
    
    println!("Direct FLAME Performance:");
    println!("  Training time: {:?}", training_time);
    println!("  Memory used: {} MB", (final_memory - initial_memory) / (1024 * 1024));
    
    // Should be faster than Candle (no compatibility overhead)
    // Should use reasonable memory
    assert!(training_time.as_secs() < 300); // 50 steps in under 5 minutes
}
```

### Agent 6 Success Criteria
- [ ] Complete training works with direct FLAME
- [ ] No Candle dependencies anywhere
- [ ] Performance better than Candle approach
- [ ] LoRA output is ComfyUI compatible
- [ ] Memory usage is reasonable

---

## Execution Timeline

### Week 1: Purge & Replace (Agents 1-2)
- Complete Candle elimination
- Direct API replacement
- Fix compilation errors

### Week 2: Training & Models (Agents 3-4)
- Training loop migration
- Model architecture conversion
- Parameter management

### Week 3: Data & Integration (Agents 5-6)
- Data pipeline migration
- End-to-end validation
- Performance testing

## Success Criteria

**COMPLETE when:**
- [ ] Zero Candle code remains anywhere
- [ ] All operations use direct FLAME APIs
- [ ] Training converges with mutable gradients
- [ ] Models work with FLAME tensors
- [ ] LoRA files are ComfyUI compatible
- [ ] Performance exceeds Candle baseline

**NO COMPATIBILITY LAYERS. NO WRAPPERS. CLEAN DIRECT MIGRATION.**
